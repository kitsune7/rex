"""
Custom Wake Word Detector using openWakeWord
Continuously listens for a custom wake word and prints detections.
"""

import os
import sys
import time
import numpy as np
import pyaudio
from openwakeword import Model
import argparse
from collections import deque
import threading
from pathlib import Path

from .model_utils import ensure_openwakeword_models


class WakeWordListener:
    def __init__(self, model_path, threshold=0.5, chunk_size=1280, cooldown_period=2.0):
        """
        Initialize the wake word listener.

        Args:
            model_path: Path to the .onnx model file
            threshold: Detection threshold (0.0 to 1.0)
            chunk_size: Audio chunk size (default 1280 for 80ms at 16kHz)
            cooldown_period: Minimum time between detections in seconds (default 2.0)
        """
        self.model_path = model_path
        self.threshold = threshold
        self.chunk_size = chunk_size
        self.cooldown_period = cooldown_period

        # Audio parameters (openWakeWord expects 16kHz, mono, int16)
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000

        # Ensure openwakeword resource models are available
        if not ensure_openwakeword_models():
            print("âŒ Failed to download required models")
            sys.exit(1)

        # Initialize model
        print(f"Loading model from: {model_path}")
        self.model = Model(wakeword_models=[model_path], inference_framework="onnx")

        # Get model name for display
        self.model_name = os.path.splitext(os.path.basename(model_path))[0]

        # Initialize PyAudio
        self.audio = pyaudio.PyAudio()
        self.stream = None

        # Detection state
        self.is_running = False
        self.detection_count = 0
        self.last_detection_time = 0

    def start_listening(self):
        """Start the audio stream and begin listening."""
        try:
            # Open audio stream
            self.stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=None,  # We'll use blocking mode
            )

            self.is_running = True
            print(f"\nğŸ¤ Listening for wake word: '{self.model_name}'")
            print(f"   Threshold: {self.threshold}")
            print(f"   Press Ctrl+C to stop\n")
            print("-" * 50)

            # Main listening loop
            while self.is_running:
                # Read audio chunk
                audio_data = self.stream.read(self.chunk_size, exception_on_overflow=False)

                # Convert bytes to numpy array
                audio_array = np.frombuffer(audio_data, dtype=np.int16)

                # Run inference
                prediction = self.model.predict(audio_array)

                # Check detection for our model
                for mdl_name, score in prediction.items():
                    if score >= self.threshold:
                        current_time = time.time()
                        if current_time - self.last_detection_time >= self.cooldown_period:
                            self.handle_detection(mdl_name, score)
                            self.last_detection_time = current_time

        except KeyboardInterrupt:
            print("\n\nğŸ›‘ Stopping listener...")
        except Exception as e:
            print(f"âŒ Error: {e}")
        finally:
            self.stop_listening()

    def handle_detection(self, model_name, score):
        """Handle wake word detection."""
        self.detection_count += 1
        timestamp = time.strftime("%H:%M:%S")

        # Print detection with formatting
        print(f"ğŸ”” [{timestamp}] WAKE WORD DETECTED! #{self.detection_count}")
        print(f"   Model: {model_name}")
        print(f"   Confidence: {score:.3f}")
        print("-" * 50)

        # Here you can add any additional logic for what happens after detection
        # For example:
        # - Play a sound
        # - Trigger another action
        # - Start recording for speech recognition

    def wait_for_detection(self):
        """
        Wait for a single wake word detection and return.
        Returns True when wake word is detected, False if interrupted.
        """
        try:
            # Open audio stream if not already open
            if self.stream is None:
                self.stream = self.audio.open(
                    format=self.format,
                    channels=self.channels,
                    rate=self.rate,
                    input=True,
                    frames_per_buffer=self.chunk_size,
                    stream_callback=None,
                )

            self.is_running = True

            # Listen until wake word is detected
            while self.is_running:
                # Read audio chunk
                audio_data = self.stream.read(self.chunk_size, exception_on_overflow=False)

                # Convert bytes to numpy array
                audio_array = np.frombuffer(audio_data, dtype=np.int16)

                # Run inference
                prediction = self.model.predict(audio_array)

                # Check detection for our model
                for mdl_name, score in prediction.items():
                    if score >= self.threshold:
                        current_time = time.time()
                        if current_time - self.last_detection_time >= self.cooldown_period:
                            self.detection_count += 1
                            self.last_detection_time = current_time
                            return True

        except KeyboardInterrupt:
            self.is_running = False
            return False
        except Exception as e:
            print(f"âŒ Wake word detection error: {e}")
            return False

    def stop_listening(self):
        """Clean up audio resources."""
        self.is_running = False

        if self.stream is not None:
            self.stream.stop_stream()
            self.stream.close()

        self.audio.terminate()

        print(f"\nğŸ“Š Total detections: {self.detection_count}")
        print("Goodbye! ğŸ‘‹")


def run_wake_word_listener(args):
    base_model_path = Path("models/wake_word_models")
    model_path = base_model_path / args.model / f"{args.model}.onnx"

    if not os.path.exists(model_path):
        print(f"âŒ Error: Model file not found at: {model_path}")
        sys.exit(1)

    if not 0.0 <= args.threshold <= 1.0:
        print(f"âŒ Error: Threshold must be between 0.0 and 1.0")
        sys.exit(1)

    listener = WakeWordListener(
        model_path=str(model_path),
        threshold=args.threshold,
        chunk_size=args.chunk_size,
        cooldown_period=args.cooldown
    )
    listener.start_listening()
